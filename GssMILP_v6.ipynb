{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GssMILP_v6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SatyaKrishna/GssMILP-Anomaly-Classification-in-Surveillance-Videos/blob/main/GssMILP_v6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biTzu42aSKOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "128b8837-8efd-47bf-84e7-cf8f80c2ac15"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS0BCaRIGTTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d705c3-6dfa-4b13-be6c-397ad852d5f4"
      },
      "source": [
        "cd /content/drive/My Drive/NSK"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/NSK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfE4lhwsGO4M"
      },
      "source": [
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import os.path\n",
        "import cvxpy as cp\n",
        "import collections as C\n",
        "from os import path\n",
        "import math\n",
        "import random\n",
        "from datetime import datetime\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.csgraph import csgraph_from_dense\n",
        "from scipy.sparse import csgraph\n",
        "from scipy.sparse import identity\n",
        "from scipy.sparse.linalg import inv\n",
        "from notebook import notebookapp\n",
        "notebookapp.iopub_data_rate_limit= 10000000.0\n",
        "notebookapp.rate_limit_window=12.0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3asKclfzVYM"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "679YBpVwSJEa"
      },
      "source": [
        "'''\n",
        "class Vertex:\n",
        "  def __init__(self, node):\n",
        "    self.id = node\n",
        "    self.adjacent = {}\n",
        "  \n",
        "  def __str__(self):\n",
        "    return str(self.id) + ' adjacent: ' + str([x.id for x in self.adjacent])\n",
        "  \n",
        "  def add_neighbor(self, neighbor, weight=0.0):\n",
        "    self.adjacent[neighbor] = weight\n",
        "  \n",
        "  def get_connections(self):\n",
        "    return self.adjacent.keys()\n",
        "  \n",
        "  def get_id(self):\n",
        "    return self.id\n",
        "  \n",
        "  def get_weight(self, neighbor):\n",
        "    return self.adjacent[neighbor]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRYYV-hqSNj7"
      },
      "source": [
        "'''\n",
        "class Graph:\n",
        "  def __init__(self):\n",
        "    self.vert_dict = {}\n",
        "    self.num_vertices = 0\n",
        "  \n",
        "  def __iter__(self):\n",
        "    return iter(self.vert_dict.values())\n",
        "  \n",
        "  def add_vertex(self, node):\n",
        "    self.num_vertices = self.num_vertices + 1\n",
        "    new_vertex = Vertex(node)\n",
        "    self.vert_dict[node] = new_vertex\n",
        "    return new_vertex\n",
        "  \n",
        "  def get_vertex(self, n):\n",
        "    if n in self.vert_dict:\n",
        "      return self.vert_dict[n]\n",
        "    else:\n",
        "      return None\n",
        "  \n",
        "  def add_edge(self, frm, to, cost = 0.0):\n",
        "    if frm not in self.vert_dict:\n",
        "      self.add_vertex(frm)\n",
        "    if to not in self.vert_dict:\n",
        "      self.add_vertex(to)\n",
        "    \n",
        "    self.vert_dict[frm].add_neighbor(self.vert_dict[to], cost)\n",
        "    self.vert_dict[to].add_neighbor(self.vert_dict[frm], cost)\n",
        "\n",
        "  def get_vertices(self):\n",
        "    return self.vert_dict.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy6QozadIOJu"
      },
      "source": [
        "def find_segment_level_labels(frame_level_labels_file, root_path_for_videos_directory, output_file,data_set):\n",
        "  \"\"\"\n",
        "  This function finds the video-segment level labels from frame level labels. The output will written in a text file in the following format.\n",
        "  \"video_segment_index label\n",
        "  video_segment_index label\n",
        "  video_segment_index label\n",
        "        ...\n",
        "        ...\n",
        "  video_segment_index label\"\n",
        "  \n",
        "  video_segment_index is a string consist three parts. i) v_type: video type ii) v_name: video name iii) s_index: segment index\n",
        "  label is either 1/-1\n",
        "  \n",
        "  \"\"\"\n",
        "  f = open(frame_level_labels_file,\"r\").readlines()\n",
        "  of = open(output_file,\"w\")\n",
        "  \n",
        "  for line in f:\n",
        "    # Ped1 eample # Abnormal_Test024_video.avi 50 160\n",
        "    # Ped2 example # Abnormal_Test001_video.avi 61 180\n",
        "    # MEM example # Abnormal_012.mp4 200 500 616 930\n",
        "    # WS example # Abuse003_x264.mp4 2148 2196\n",
        "    words = line.strip().split(' ')\n",
        "    if data_set == 'Ped1':\n",
        "      v_name = words[0] # Abnormal_Test024.mp4\n",
        "      v_type = v_name.split('_')[0] # Abnormal\n",
        "      v_name = v_name.replace(v_type+'_','') # Test024_video.avi\n",
        "      v_name = v_name.replace(\".avi\",\".txt\")\n",
        "    if data_set == 'Ped2':\n",
        "      v_name = words[0] # Abnormal_Test001_video.avi\n",
        "      v_type = v_name.split('_')[0] # Abnormal\n",
        "      v_name = v_name.replace(v_type+'_','') # Test001_video.avi\n",
        "      v_name = v_name.replace(\".avi\",\".txt\") # Test001_video.txt      \n",
        "    if data_set == 'MEM':\n",
        "      v_name = words[0] # Abnormal_012.mp4\n",
        "      v_type = v_name.split('_')[0] # Abnormal\n",
        "      v_name = v_name.replace(v_type+'_','') # 012.mp4\n",
        "      v_name = v_name.replace(\".mp4\",\".txt\") # 012.txt\n",
        "    if data_set == 'WS':\n",
        "      v_name = words[0] # Abuse003_x264.mp4\n",
        "      if 'Normal' in v_name:\n",
        "        v_type = 'Normal'\n",
        "      else:\n",
        "        v_type = 'Abnormal'\n",
        "      v_name = v_name.replace(\".mp4\",\".txt\") # Abuse003_x264.txt\n",
        "\n",
        "    if int(words[1]) == -1 and int(words[2]) == -1 :\n",
        "      for i in range(32):\n",
        "        string = \"{}_{}_{} {}\\n\".format(v_type,v_name,i,-1)\n",
        "        of.write(string)\n",
        "    else:\n",
        "      length = len(words)\n",
        "      no_of_frames = 0\n",
        "      # the following statement take more time while running the code in colab\n",
        "      #no_of_frames = len(glob.glob(root_path_for_video_frames_directory+v_type+\"/\"+v_name.replace(\"_C.txt\",\"\")+\"/\"+\"*.jpg\"))\n",
        "      if data_set == 'Ped1':\n",
        "        v_path = root_path_for_videos_directory+v_type+'/'+v_name.replace('.txt','avi')\n",
        "        cap = cv2.VideoCapture(v_path)\n",
        "        no_of_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "        no_of_frames = int(no_of_frames)\n",
        "        cap.release()\n",
        "      if data_set == 'Ped2':\n",
        "        v_path = root_path_for_videos_directory+v_type+'/'+v_name.replace('.txt','avi')\n",
        "        cap = cv2.VideoCapture(v_path)\n",
        "        no_of_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "        no_of_frames = int(no_of_frames)\n",
        "        cap.release()\n",
        "      if data_set == 'MEM':\n",
        "        v_path = root_path_for_videos_directory+v_type+'/'+v_name.replace('.txt','.mp4')\n",
        "        cap = cv2.VideoCapture(v_path)\n",
        "        no_of_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "        no_of_frames = int(no_of_frames)\n",
        "        cap.release()\n",
        "      if data_set == 'WS':\n",
        "        v_path = root_path_for_videos_directory+v_type+'/'+v_name.replace('.txt','.mp4')\n",
        "        cap = cv2.VideoCapture(v_path)\n",
        "        no_of_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "        no_of_frames = int(no_of_frames)\n",
        "        cap.release()\n",
        "      if no_of_frames <= 1024:\n",
        "        no_of_frames = no_of_frames + (1056 - no_of_frames)\n",
        "\n",
        "      line_space_list = np.linspace(0,no_of_frames,33)\n",
        "      line_space_list = [int(round(x)) for x in line_space_list]\n",
        "      for i in range(32):\n",
        "        string = \"{}_{}_{} {}\\n\".format(v_type,v_name,i,-1)\n",
        "        SS = line_space_list[i]+1\n",
        "        SE = line_space_list[i+1]-1\n",
        "        \n",
        "        w = 1\n",
        "        while w < length:\n",
        "          if SS <= int(words[w]) and int(words[w+1]) <= SE:\n",
        "            string = \"{}_{}_{} {}\\n\".format(v_type,v_name,i,1)\n",
        "            break\n",
        "          elif SS >= int(words[w]) and SS < int(words[w+1]) and SE >= int(words[w+1]):\n",
        "            string = \"{}_{}_{} {}\\n\".format(v_type,v_name,i,1)\n",
        "            break\n",
        "          elif SS < int(words[w]) and SE > int(words[w]) and SE <= int(words[w+1]):\n",
        "            string = \"{}_{}_{} {}\\n\".format(v_type,v_name,i,1)\n",
        "            break\n",
        "          elif SS >= int(words[w]) and SE <= int(words[w+1]) :\n",
        "            string = \"{}_{}_{} {}\\n\".format(v_type,v_name,i,1)\n",
        "            break\n",
        "          else:\n",
        "            w = w+2\n",
        "        of.write(string)\n",
        "  of.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueOSku08OY11"
      },
      "source": [
        "# Following lines for testing the above function\n",
        "#frame_level_labels_file = \"./dataset/Temporal_Anomaly_Annotations_for_full_data_of_ped2.txt\"\n",
        "#root_path_for_videos_directory = './AllVideos/UCSD_Ped2/'\n",
        "#output_file = \"./dataset/segment_level_labels_ped2.txt\"\n",
        "#data_set = 'Ped2'\n",
        "#find_segment_level_labels(frame_level_labels_file, root_path_for_videos_directory, output_file,data_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWvP6rUfMEb5"
      },
      "source": [
        "def combining_video_features(videos_path,segment_level_labels_file_path, feat_option):\n",
        "  \"\"\"\n",
        "    This function combines the all types of video featues in to a single list of list datastructure as shown below:\n",
        "    [ [key, feature_vector, label],\n",
        "      [key, feature_vector, label],\n",
        "\n",
        "      [key, feature_vector, label] ]. \n",
        "    \n",
        "    key is a string type. it contains three parts. 1: first part is the type of video, \n",
        "                                                   2. second part denotes the name of the video and \n",
        "                                                   3. Third part denotes the index of video segment. \n",
        "    Ex: Arrest_Arrest001_x264_C.txt_0. For each index key it contains a list of 4096 features and one label\n",
        "    feature_vector: it is a list of 4096 float numbers\n",
        "    label: it is an integer\n",
        "\n",
        "    arguments: \n",
        "    1. videos_path: it will take the root path of all types of anomaly folders in which we have one text file of 32 features for each video \n",
        "    Ex: videos_path=\"/media/cloud/data2/AnomalyDetectionCVPR2018/C3D-features-for-Training-and-Testing-on-WS/Train/\"\n",
        "    2. segment_level_labels_file_path: \n",
        "    Ex: \"/media/cloud/data2/AnomalyDetectionCVPR2018/ADVS-new-code/dataset/segment_level_labels_WS.txt\"\n",
        "  \"\"\"\n",
        "  \n",
        "  local_dataset = []\n",
        "  local_dataset_labels = {}\n",
        "  \n",
        "  f = open(segment_level_labels_file_path,\"r\").readlines()\n",
        "  for line in f:\n",
        "    w = line.strip().split(' ')\n",
        "    local_dataset_labels[w[0]] = int(w[1])\n",
        "  \n",
        "  abnormal_types = os.listdir(videos_path+'/'+'1'+'/')\n",
        "  #print(abnormal_types)\n",
        "  for v_type in abnormal_types:\n",
        "    videos_list = os.listdir(videos_path+'/'+'1'+'/'+v_type+'/')\n",
        "    #print(videos_list)\n",
        "    for v_name in videos_list:\n",
        "      #print(v_name)\n",
        "      if feat_option == 1:\n",
        "        f = open(videos_path+'/'+'1'+'/'+v_type+'/'+v_name,'r').readlines()\n",
        "        for s_index in range(32):\n",
        "          #local_dataset[v_type+\"_\"+v_name+\"_\"+str(s_index)] = f[s_index].strip().split(' ')  # this statement is used if\n",
        "          local_dataset.append([v_type+\"_\"+v_name+\"_\"+str(s_index), [float(e) for e in f[s_index].strip().split(' ')],  local_dataset_labels[v_type+\"_\"+v_name+\"_\"+str(s_index)] ])\n",
        "        #f.close()\n",
        "      if feat_option == 2:\n",
        "        if not (path.exists(videos_path+'/'+'2'+'/'+v_type+'/'+v_name) and path.exists(videos_path+'/'+'3'+'/'+v_type+'/'+v_name) and path.exists(videos_path+'/'+'4'+'/'+v_type+'/'+v_name) ):\n",
        "          print('FileNotExists - ERROR:')\n",
        "          print(videos_path+'/'+'2'+'/'+v_type+'/'+v_name)\n",
        "          print(videos_path+'/'+'3'+'/'+v_type+'/'+v_name)\n",
        "          print(videos_path+'/'+'4'+'/'+v_type+'/'+v_name)\n",
        "          sys.exit()\n",
        "        f2 = open(videos_path+'/'+'2'+'/'+v_type+'/'+v_name,'r').readlines()\n",
        "        f3 = open(videos_path+'/'+'3'+'/'+v_type+'/'+v_name,'r').readlines()\n",
        "        f4 = open(videos_path+'/'+'4'+'/'+v_type+'/'+v_name,'r').readlines()\n",
        "        for s_index in range(32):\n",
        "          l2 = [float(e) for e in f2[s_index].strip().split(' ')]\n",
        "          l3 = [float(e) for e in f3[s_index].strip().split(' ')]\n",
        "          l4 = [float(e) for e in f4[s_index].strip().split(' ')]\n",
        "          local_dataset.append([v_type+\"_\"+v_name+\"_\"+str(s_index), l2 + l3 + l4,  local_dataset_labels[v_type+\"_\"+v_name+\"_\"+str(s_index)] ])\n",
        "        #f2.close()\n",
        "        #f3.close()\n",
        "        #f4.close()\n",
        "      if feat_option == 3:\n",
        "        if not (path.exists(videos_path+'/'+'1'+'/'+v_type+'/'+v_name) and path.exists(videos_path+'/'+'2'+'/'+v_type+'/'+v_name) and path.exists(videos_path+'/'+'3'+'/'+v_type+'/'+v_name) and path.exists(videos_path+'/'+'4'+'/'+v_type+'/'+v_name) ):\n",
        "          print('FileNotExists - ERROR:')\n",
        "          print(videos_path+'/'+'1'+'/'+v_type+'/'+v_name)\n",
        "          print(videos_path+'/'+'2'+'/'+v_type+'/'+v_name)\n",
        "          print(videos_path+'/'+'3'+'/'+v_type+'/'+v_name)\n",
        "          print(videos_path+'/'+'4'+'/'+v_type+'/'+v_name)\n",
        "          sys.exit()\n",
        "        f1 = open(videos_path+'/'+'1'+'/'+v_type+'/'+v_name,'r').readlines()\n",
        "        f2 = open(videos_path+'/'+'2'+'/'+v_type+'/'+v_name,'r').readlines()\n",
        "        f3 = open(videos_path+'/'+'3'+'/'+v_type+'/'+v_name,'r').readlines()\n",
        "        f4 = open(videos_path+'/'+'4'+'/'+v_type+'/'+v_name,'r').readlines()\n",
        "        for s_index in range(32):\n",
        "          l1 = [float(e) for e in f1[s_index].strip().split(' ')]\n",
        "          l2 = [float(e) for e in f2[s_index].strip().split(' ')]\n",
        "          l3 = [float(e) for e in f3[s_index].strip().split(' ')]\n",
        "          l4 = [float(e) for e in f4[s_index].strip().split(' ')]\n",
        "          local_dataset.append([v_type+\"_\"+v_name+\"_\"+str(s_index), l1 + l2 + l3 + l4,  local_dataset_labels[v_type+\"_\"+v_name+\"_\"+str(s_index)] ])\n",
        "        #f1.close()\n",
        "        #f2.close()\n",
        "        #f3.close()\n",
        "        #f4.close()\n",
        "        \n",
        "  return local_dataset,local_dataset_labels"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKdExNCyPBa8"
      },
      "source": [
        "# Following lines for testing the above function\n",
        "#videos_path='./dataset/Ped2_dataset_1'\n",
        "#segment_level_labels_file_path = './dataset/segment_level_labels_ped2.txt'\n",
        "#features_option = 3\n",
        "#dataset, labels = combining_video_features(videos_path, segment_level_labels_file_path,features_option)\n",
        "#print(\"Dataset Inf: Number of instances - {}, Number of labes {}\".format(len(dataset),len(labels)))\n",
        "#print('Lenth of feature vector: {}'.format(len(dataset[0][1])))\n",
        "#print(\"A DICTIONARY OF FEATURES AND A DICTIONARY OF LABELS ARE CREATED.\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GukI-90G9clA"
      },
      "source": [
        "# Python program to print connected  \n",
        "# components in an undirected graph \n",
        "class Graph: \n",
        "      \n",
        "    # init function to declare class variables \n",
        "    def __init__(self,V): \n",
        "        self.V = V \n",
        "        self.adj = [[] for i in range(V)] \n",
        "  \n",
        "    def DFSUtil(self, temp, v, visited): \n",
        "  \n",
        "        # Mark the current vertex as visited \n",
        "        visited[v] = True\n",
        "  \n",
        "        # Store the vertex to list \n",
        "        temp.append(v) \n",
        "  \n",
        "        # Repeat for all vertices adjacent \n",
        "        # to this vertex v \n",
        "        for i in self.adj[v]: \n",
        "            if visited[i] == False: \n",
        "                  \n",
        "                # Update the list \n",
        "                temp = self.DFSUtil(temp, i, visited) \n",
        "        return temp \n",
        "  \n",
        "    # method to add an undirected edge \n",
        "    def addEdge(self, v, w): \n",
        "        self.adj[v].append(w) \n",
        "        self.adj[w].append(v) \n",
        "  \n",
        "    # Method to retrieve connected components \n",
        "    # in an undirected graph \n",
        "    def connectedComponents(self): \n",
        "        visited = [] \n",
        "        cc = [] \n",
        "        for i in range(self.V): \n",
        "            visited.append(False) \n",
        "        for v in range(self.V): \n",
        "            if visited[v] == False: \n",
        "                temp = [] \n",
        "                cc.append(self.DFSUtil(temp, v, visited)) \n",
        "        return cc"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zratRbIdwBf1"
      },
      "source": [
        "# Graph Construction\n",
        "def graph_construction(neighbors,dataset):\n",
        "  neighbors=neighbors\n",
        "  time_before = datetime.now() # starting time for graph construction\n",
        "  X = []\n",
        "  for i in range(len(dataset)):\n",
        "    X.append(dataset[i][1])\n",
        "  X = np.array(X)\n",
        "  nbrs_graph = NearestNeighbors(n_neighbors=neighbors, algorithm='ball_tree', metric = 'euclidean',n_jobs = 24).fit(X)  #keyword argument 'algorithm', which must be one of ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "  distances, indices = nbrs_graph.kneighbors(X)\n",
        "  print(\"Time taken for K-NN graph construction: {}\".format(datetime.now() - time_before))\n",
        "  return distances, indices"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHbvaWE-o6N5"
      },
      "source": [
        "#import numpy as np\n",
        "#import cvxpy as cp\n",
        "#import collections as C\n",
        "\n",
        "#def NCGssMILP(W, y,  Iy, lambda1, lambda2a, lambda2b, lambda3, L,PL, NL, n, N):\n",
        "#def NCGssMILP(GL,  Iy, lambda1, lambda2a, lambda2b, lambda3, L,PL, NL, n, N):\n",
        "def NCGssMILP(W,GL, indices, Iy, lambda1, lambda2a, lambda2b, lambda3, L,PL, NL, n, N):\n",
        "  \"\"\"\n",
        "  W : weighted similarity matrix of size 'n x n'\n",
        "  y : actual bag-level labels\n",
        "  Iy : List of lists contains the instance-level actual labels\n",
        "  lambda1 : hyperperameter used as the coefficient of term-2\n",
        "  lambda2a : hyperperameter used as the coefficient of term-3\n",
        "  lambda2b : hyperperameter used as the coefficient of term-4\n",
        "  lambda3 : hyperperameter used as the coefficient of term-5\n",
        "  L : Total number of labeled bags\n",
        "  PL : Total number of positive labeled bags\n",
        "  NL : Total number of negative labeled bags\n",
        "  n : Total number of instances\n",
        "  N : Toatal number of bags\n",
        "\n",
        "  Output : y_star belongs to {+1,-1}\n",
        "  \"\"\"\n",
        "  threshold_value = 0.000001\n",
        "  # Cmputing total positive labeled instances and negative labeled instances\n",
        "  # Converting bag level labels to Instance-level labels\n",
        "  nplI =  PL * 32\n",
        "  nnlI = NL * 32\n",
        "  #print('No.of positive labeled instances : {}'.format(nplI))\n",
        "  #print('No.of negative labeled instances : {}'.format(nnlI))\n",
        "\n",
        "  # computation of hyperparameters and initial value of f\n",
        "  alpha = n/(2 * (nplI + nnlI))\n",
        "  # computation of F* = Invers((I - alpha S))*Y\n",
        "  IY = csr_matrix(np.reshape(np.array(Iy),[n,1]))\n",
        "  f_star = np.squeeze(inv(identity(n) - GL.multiply(alpha)).dot(IY).toarray())\n",
        "  g = []\n",
        "  for i in range(n):\n",
        "    if f_star[i] >= 0.0:\n",
        "      g.append(1.0)\n",
        "    else:\n",
        "      g.append(-1.0)\n",
        "  g = np.array(g)\n",
        "  beta = np.dot(np.dot(g.transpose(),L),g)\n",
        "\n",
        "  lambda3 = (2.0 * beta) / (n - (nplI + nnlI))\n",
        "  lambda2a = (nnlI * alpha)/ (nplI + nnlI)\n",
        "  lambda2b = (nplI * alpha)/ (nplI + nnlI)\n",
        "\n",
        "  # Initial guess f_zero\n",
        "  #f_zero = np.random.rand(n)\n",
        "  #f_zero = f_zero * 2.0 - 1.0\n",
        "  \n",
        "  f_zero = f_star\n",
        "  \n",
        "  # Initialization of f_new\n",
        "  f_new = np.array(list(f_zero))\n",
        "  #xi = np.random.uniform(size=PL)\n",
        "  xi = cp.Variable(PL)\n",
        "  Iteration = 0\n",
        "  while Iteration <= 50:\n",
        "    f_old = np.array(list(f_new))\n",
        "    f = cp.Variable(n)\n",
        "    #xi = cp.Variable(PL)\n",
        "    #xi = np.random.uniform(size=PL)\n",
        "    #print('xi value : {}'.format(xi))\n",
        "\n",
        "    # code for term1 f^TLf\n",
        "    #expr1 = cp.quad_form(f, GL)\n",
        "    \n",
        "    #expr1 = np.dot(np.dot(cp.reshape(f,[1,n]),GL),f)\n",
        "    \n",
        "    #temp_expr1 = cp.multiply(cp.reshape(f,[1,n]) , GL)\n",
        "    #expr1 = cp.multiply(temp_expr1 , f)\n",
        "    \n",
        "    #temp_expr1 = GL*f\n",
        "    #expr1 = temp_expr1.T * f\n",
        "    \n",
        "    #temp_expr1 = cp.atoms.affine.transpose.transpose(f)*GL\n",
        "    #expr1 = temp_expr1*f\n",
        "    #Sum = 0.0\n",
        "    #for i in range(n):\n",
        "    #  i_neighbours_indices = []\n",
        "    #  for j in range(number_of_neighbours):\n",
        "    #    i_neighbours_indices.append(indices[i][j])\n",
        "    #  \n",
        "    #  for neighbour_index in i_neighbours_indices:\n",
        "    #    Sum = Sum + W[i][neighbour_index] * cp.square(f[i] - f[neighbour_index])\n",
        "    #expr1 = Sum / n\n",
        "    Sum = 0.0\n",
        "    for i in range(n):\n",
        "     for j in indices[i]:\n",
        "       Sum = Sum + W[i][j] * cp.square(f[i] - f[j])\n",
        "    expr1 = Sum / n\n",
        "\n",
        "    \n",
        "\n",
        "    # code for term2 : temporal smoothness\n",
        "    expr2 = lambda1 * cp.sum_squares(f[nplI:nplI+nnlI] - f[nplI+1:nplI+nnlI+1])\n",
        "\n",
        "    # code for term3 : meansquare error over negative instances \n",
        "    expr3 = lambda2a * cp.sum_squares(f[nplI:nplI+nnlI] + np.ones(nnlI)) \n",
        "\n",
        "    # code for term4 : meansquare error meansquare error over positive instances\n",
        "    expr4 = lambda2b * cp.sum_squares(xi)\n",
        "\n",
        "    # code for term5 : \n",
        "    expr5 = lambda3 * cp.sum(cp.multiply(f[nplI+nnlI:n],f_old[nplI+nnlI:n]))   \n",
        "    \n",
        "    #obj_function = cp.Minimize(expr1+expr2+expr3+expr4+expr5)\n",
        "    obj_function = cp.Minimize(expr1+expr2+expr3+expr4-expr5)\n",
        "\n",
        "    # code for constraints\n",
        "    # code for constraint1\n",
        "    const1 = [f >= -1.0, f <= 1.0]\n",
        "\n",
        "    # code for constraint2\n",
        "    # 1. reshape the f_old into list of lists\n",
        "    # 2. compute delta matrix and max vector for positive bags\n",
        "    # 3. define constraint2\n",
        "\n",
        "    #f_old_lists = f_old.reshape((-1,32))\n",
        "    f_old_lists = f_old.reshape((-1,32))[0:PL,] # selecting only positive labeled instances\n",
        "    #print('Shape : {}'.format(f_old_lists.shape))\n",
        "    number_of_bags = np.shape(f_old_lists)[0]\n",
        "    if number_of_bags == PL:\n",
        "      #print(\"number of bags are matched\")\n",
        "      pass\n",
        "    else:\n",
        "      print(\"      - Logical error: Number of bags are not matched\")\n",
        "    zeta = np.max(f_old_lists,axis=1) # list of maximum label score from each positive bag\n",
        "    #print('zeta : {}'.format(zeta))\n",
        "\n",
        "    maximum_value_counts = [C.Counter(list(f_old_lists[i]))[zeta[i]] for i in range(len(zeta))] # finding count of maximum label score in each bag\n",
        "    #print(maximum_value_counts)\n",
        "    \n",
        "    delta = np.zeros((PL,32))\n",
        "    for r_index in range(PL):\n",
        "      max_value = zeta[r_index]\n",
        "      for c_index in range(32):\n",
        "        if f_old_lists[r_index,c_index] == max_value:\n",
        "          delta[r_index,c_index] = 1.0/maximum_value_counts[r_index]\n",
        "    #print('reshape output - : {}'.format(cp.reshape(f,[32,N])[0:32,0:PL]))\n",
        "    #print('f_old[0:PL] : {}'.format(f_old[0:PL]))\n",
        "    #print('Shape of Delta is : {}'.delta.shape)\n",
        "    #print('Delta : \\n {}'.format(delta))\n",
        "    \n",
        "    temp_expr = np.dot(delta, cp.reshape(f,[32,N])[0:32,0:PL] - cp.reshape(f_old,[32,N])[0:32,0:PL])\n",
        "    temp1 = temp_expr.diagonal()\n",
        "    temp2 = np.subtract(np.subtract(np.ones(PL), zeta),temp1)\n",
        "    const2 = [temp2[i] <= xi[i] for i in range(PL)] #temp2 <= xi\n",
        "\n",
        "\n",
        "    # code for constraint3\n",
        "    const3 = [xi >= 0.0]\n",
        "\n",
        "    #constraints = const1 + const2 + const3\n",
        "    constraints = const1+const2+const3\n",
        "    prob = cp.Problem(obj_function, constraints)\n",
        "    #prob.solve(solver=cp.SCS, use_indirect=True)\n",
        "    #prob.solve(solver=cp.OSQP, verbose=True,max_iter = 35000)\n",
        "    prob.solve(solver=cp.OSQP, max_iter = 185000)\n",
        "    f_new = f.value\n",
        "    Norm_value = cp.norm((f_new - f_old),1).value\n",
        "    print('      Iteration No : {} \\t Norm value : {}'.format(Iteration, Norm_value))\n",
        "    if  Norm_value <= threshold_value :\n",
        "      break\n",
        "    Iteration = Iteration + 1\n",
        "  return f_new"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsfrhE_A6X5l"
      },
      "source": [
        "def Labeled_and_Unlabeled_datapreparation(DoS, videos_path, segment_level_labels_file_path, dataset, labels):\n",
        "    \"\"\"\n",
        "        This function selects the training(labeled) videos randomly from each type of videos with uniform distrbution based on DoS value and then \n",
        "        the rest are considered as unlabeled data. For GssMILP, the features are arranged as D = {L^{+}, L^{-}, U}.\n",
        "        Here, D : set of features\n",
        "              L^{+} : subset of positive labeled data points\n",
        "              L^{-} : subset of negative labeled data points\n",
        "              U : subset of Unlabeled data points\n",
        "              L = L^{+} + L^{-} : number of labeled points\n",
        "              U = number of Unlabeled points\n",
        "              L+U = N : total number of data points\n",
        "                \n",
        "    arguments:\n",
        "            DoS: It is float data type. It denotes the percentage of labeld data to be consider for supervision.\n",
        "            videos_path: It is string type, denotes the dataset path, in which we have a folder for each type of videos and named with integer numbers.\n",
        "                    Ex: dataset_ptah = \"/media/cloud/data2/AnomalyDetectionCVPR2018/C3D-features-for-Training-and-Testing-on-WS/Train/\"\n",
        "            segment_level_labels_file_path: \"/media/cloud/data2/AnomalyDetectionCVPR2018/ADVS-new-code/dataset/segment_level_labels_WS.txt\"\n",
        "            #no_abnormal_types: It is integer type. It indicates the how many different types (classes) of videos considered.   \n",
        "    \"\"\"\n",
        "    totalInstances = len(dataset)\n",
        "    totalNumberOfVideos = int(totalInstances/32)\n",
        "    \n",
        "    # finding list of different abnormal type of videos exist in dataset\n",
        "    abnormal_types = os.listdir(videos_path+'/'+'1'+'/')\n",
        "    no_abnormal_types = len(abnormal_types)\n",
        "    print(\"   Number of abnormal types in dataset is: {}\".format(len(abnormal_types)))\n",
        "    \n",
        "    \n",
        "    # Calculation of no of videos have to be select from each class and  total no.of labeled videos\n",
        "    nlv = 0\n",
        "    nlv_per_anomaly_type = {}\n",
        "    for video_type in abnormal_types:\n",
        "        nlv_per_anomaly_type[video_type] = int( math.ceil(len(os.listdir(videos_path+'/'+'1'+'/'+video_type)) * DoS/100.0) )\n",
        "        nlv = nlv + nlv_per_anomaly_type[video_type]\n",
        "    print(\"   Number of labeled videos: {}\".format(nlv))\n",
        "\n",
        "    # select video indices randomly from each type of videos based on the value of 'nlp_per_anomaly_type'\n",
        "    labeled_video_samples = []\n",
        "    unlabeled_video_samples = []\n",
        "    labeled_samples_indices = []\n",
        "    unlabeled_samples_indices = []\n",
        "    actual_labels_of_labeled_samples_points = []\n",
        "    actual_labels_of_unlabeled_samples_points = []\n",
        "\n",
        "    dataset_1 = {}\n",
        "    for i in range(totalInstances):\n",
        "        dataset_1[dataset[i][0]] = dataset[i][1]\n",
        "    abnormal_types.remove('Normal')\n",
        "    for v_type in abnormal_types:\n",
        "        videos_list = os.listdir(videos_path+'/'+'1'+'/'+ v_type)\n",
        "        v_indices = random.sample( range(0,len(videos_list)), nlv_per_anomaly_type[v_type] )\n",
        "\n",
        "        for v_index in v_indices:\n",
        "            v_name = videos_list[v_index]\n",
        "            for s_index in range(32):\n",
        "                labeled_video_samples.append(dataset_1[v_type+\"_\"+v_name+\"_\"+str(s_index)])\n",
        "                labeled_samples_indices.append(v_type+\"_\"+v_name+\"_\"+str(s_index))\n",
        "                actual_labels_of_labeled_samples_points.append(labels[v_type+\"_\"+v_name+\"_\"+str(s_index)])\n",
        "        for index in range(0,len(videos_list)):\n",
        "            if index not in v_indices:\n",
        "                v_name = videos_list[index]\n",
        "                for s_index in range(32):\n",
        "                    unlabeled_video_samples.append(dataset_1[v_type+\"_\"+v_name+\"_\"+str(s_index)])\n",
        "                    unlabeled_samples_indices.append(v_type+\"_\"+v_name+\"_\"+str(s_index))\n",
        "                    actual_labels_of_unlabeled_samples_points.append(labels[v_type+\"_\"+v_name+\"_\"+str(s_index)])\n",
        "    PLP = len(labeled_video_samples)   # Number of positive labeled points\n",
        "    videos_list = os.listdir(videos_path+'/'+'1'+'/'+ 'Normal')\n",
        "    v_indices = random.sample( range(0,len(videos_list)), nlv_per_anomaly_type['Normal'] )\n",
        "    for v_index in v_indices:\n",
        "        v_name = videos_list[v_index]\n",
        "        for s_index in range(32):\n",
        "            labeled_video_samples.append(dataset_1['Normal'+\"_\"+v_name+\"_\"+str(s_index)])\n",
        "            labeled_samples_indices.append('Normal'+\"_\"+v_name+\"_\"+str(s_index))\n",
        "            actual_labels_of_labeled_samples_points.append(labels['Normal'+\"_\"+v_name+\"_\"+str(s_index)])\n",
        "    for index in range(0,len(videos_list)):\n",
        "        if index not in v_indices:\n",
        "            v_name = videos_list[index]\n",
        "            for s_index in range(32):\n",
        "                unlabeled_video_samples.append(dataset_1['Normal'+\"_\"+v_name+\"_\"+str(s_index)])\n",
        "                unlabeled_samples_indices.append('Normal'+\"_\"+v_name+\"_\"+str(s_index))\n",
        "                actual_labels_of_unlabeled_samples_points.append(labels['Normal'+\"_\"+v_name+\"_\"+str(s_index)])\n",
        "    \n",
        "    NLP = len(labeled_video_samples) - PLP                        # Number of negative labeled points\n",
        "    ULP = totalInstances - (PLP + NLP)                      # Number of unlabeled points\n",
        "    return labeled_video_samples, unlabeled_video_samples, actual_labels_of_labeled_samples_points, actual_labels_of_unlabeled_samples_points, labeled_samples_indices, unlabeled_samples_indices, PLP, NLP, ULP"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR7XpvbzjUNY"
      },
      "source": [
        "#=============================================================================================\n",
        "\"Function to find the frame level predicted labels for a given sgment level labels of a video\"\n",
        "#=============================================================================================\n",
        "def find_frame_level_predicted_labels(segment_level_predictions,numberOfFrames):\n",
        "    #print(\"SEGMENT LEVEL PREDICTIONS\")\n",
        "    #print(segment_level_predictions)\n",
        "    NFrames=numberOfFrames\n",
        "    ls = list(np.linspace(0,NFrames,33))\n",
        "    ls = [int(round(x)) for x in ls]\n",
        "    slp = segment_level_predictions\n",
        "    flp = list(np.ones(NFrames)*-1)\n",
        "    for i in range(32):\n",
        "        if slp[i] >= 0.0:\n",
        "            for j in range(ls[i],ls[i+1],1):\n",
        "                flp[j] = 1.0\n",
        "    #print(flp)\n",
        "    return flp"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH1axwZwjmDz"
      },
      "source": [
        "#=============================================================================================================\n",
        "\"Function to find the frame level predicted labels for a given sgment level labels of all videos in test data\"\n",
        "#=============================================================================================================\n",
        "def find_frame_level_predictions_for_testdata(predictions,segments_list_in_testdata, root_path_for_videos_directory, data_set):\n",
        "  NVideos = int(len(predictions)/32)\n",
        "  #print(\"   Number of segments for testing: {}\".format(len(predictions)))\n",
        "  #print(\"   Number of videos for tesing: {}\".format(NVideos))\n",
        "  FLresults = []\n",
        "  NFrames = 0\n",
        "  for i in range(NVideos):\n",
        "    sname = segments_list_in_testdata[i*32] #Abnormal_Test001_video.txt_0\n",
        "    if data_set == 'Ped2' or data_set == 'Ped1':\n",
        "      if sname.find('Normal') == -1:\n",
        "        v_type = 'Abnormal'\n",
        "        v_name = sname.replace('Abnormal_','')\n",
        "      elif sname.find('Abnormal') == -1:\n",
        "        v_type = 'Normal'\n",
        "        v_name = sname.replace('Normal_','')\n",
        "      else:\n",
        "        print('SOMETHING WRONG WHILE GETING THE VIDEO FILE NAME FOR THE SEGMENT : {}'.format(sname))\n",
        "        sys.exit()\n",
        "      v_name = v_name.replace('.txt','.avi')\n",
        "      v_name = v_name.replace('_'+v_name.strip().split('_')[-1],'')\n",
        "    if data_set == 'MEM':\n",
        "      if sname.find('Normal') == -1:\n",
        "        v_type = 'Abnormal'\n",
        "        v_name = sname.replace('Abnormal_','')\n",
        "      elif sname.find('Abnormal') == -1:\n",
        "        v_type = 'Normal'\n",
        "        v_name = sname.replace('Normal_','')\n",
        "      else:\n",
        "        print('SOMETHING WRONG WHILE GETING THE VIDEO FILE NAME FOR THE SEGMENT : {}'.format(sname))\n",
        "        sys.exit()\n",
        "      v_name = v_name.replace('.txt','.mp4')\n",
        "      v_name = v_name.replace('_'+v_name.strip().split('_')[-1],'')\n",
        "    if data_set == 'WS':\n",
        "      if sname.find('Normal') == -1:\n",
        "        v_type = 'Abnormal'\n",
        "        v_name = sname.replace('Abnormal_','')\n",
        "      elif sname.find('Abnormal') == -1:\n",
        "        v_type = 'Normal'\n",
        "        v_name = sname.replace('Normal_','')\n",
        "      else:\n",
        "        print('SOMETHING WRONG WHILE GETING THE VIDEO FILE NAME FOR THE SEGMENT : {}'.format(sname))\n",
        "        sys.exit()\n",
        "      v_name = v_name.replace('.txt','.mp4')\n",
        "      v_name = v_name.replace('_'+v_name.strip().split('_')[-1],'')\n",
        "\n",
        "    v_path = root_path_for_videos_directory+v_type+'/'+v_name\n",
        "    cap = cv2.VideoCapture(v_path)\n",
        "    NFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    NFrames = int(NFrames)\n",
        "    cap.release()\n",
        "    if NFrames <= 1024:\n",
        "      NFrames = NFrames + (1056 - NFrames)\n",
        "    \n",
        "    flresults = find_frame_level_predicted_labels(predictions[i*32:i*32+32],NFrames)\n",
        "    FLresults = FLresults + flresults\n",
        "  return FLresults"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gUiNdvajoUx"
      },
      "source": [
        "#=============================================================================================================\n",
        "\"Function to find the frame level true labels for a given testdata\"\n",
        "#=============================================================================================================\n",
        "def find_frame_level_true_labels(temporal_annotations_file,segments_list_in_testdata,root_path_for_videos_directory,data_set):\n",
        "  # get temporal information\n",
        "  TA_file = temporal_annotations_file\n",
        "  lines = open(TA_file,'r').readlines()\n",
        "  TA_dict = {}\n",
        "  for line in lines:\n",
        "    w = line.strip().split(' ')\n",
        "    TA_dict[w[0]] = w[1:]\n",
        "  \n",
        "  FLTrueLabels = []\n",
        "  NVideos = int(len(segments_list_in_testdata)/32)\n",
        "\n",
        "  NFrames = 0\n",
        "  for i in range(NVideos):\n",
        "    sname = segments_list_in_testdata[i*32] #Abnormal_Vandalism049_x264_C.txt_0\n",
        "    if data_set == 'Ped1':\n",
        "      if sname.find('Normal') == -1:\n",
        "        v_type = 'Abnormal'\n",
        "        v_name = sname.replace('Abnormal_','')\n",
        "      elif sname.find('Abnormal') == -1:\n",
        "        v_type = 'Normal'\n",
        "        v_name = sname.replace('Normal_','')\n",
        "      else:\n",
        "        print('SOMETHING WRONG WHILE GETING THE VIDEO FILE NAME FOR THE SEGMENT : {}'.format(sname))\n",
        "        sys.exit()\n",
        "      v_name = v_name.replace('.txt','.avi')\n",
        "      v_name = v_name.replace('_'+v_name.strip().split('_')[-1],'')\n",
        "    if data_set == 'Ped2':\n",
        "      if sname.find('Normal') == -1:\n",
        "        v_type = 'Abnormal'\n",
        "        v_name = sname.replace('Abnormal_','')\n",
        "      elif sname.find('Abnormal') == -1:\n",
        "        v_type = 'Normal'\n",
        "        v_name = sname.replace('Normal_','')\n",
        "      else:\n",
        "        print('SOMETHING WRONG WHILE GETING THE VIDEO FILE NAME FOR THE SEGMENT : {}'.format(sname))\n",
        "        sys.exit()\n",
        "      v_name = v_name.replace('.txt','.avi')\n",
        "      v_name = v_name.replace('_'+v_name.strip().split('_')[-1],'')\n",
        "    if data_set == 'MEM':\n",
        "      if sname.find('Normal') == -1:\n",
        "        v_type = 'Abnormal'\n",
        "        v_name = sname.replace('Abnormal_','')\n",
        "      elif sname.find('Abnormal') == -1:\n",
        "        v_type = 'Normal'\n",
        "        v_name = sname.replace('Normal_','')\n",
        "      else:\n",
        "        print('SOMETHING WRONG WHILE GETING THE VIDEO FILE NAME FOR THE SEGMENT : {}'.format(sname))\n",
        "        sys.exit()\n",
        "      v_name = v_name.replace('.txt','.mp4')\n",
        "      v_name = v_name.replace('_'+v_name.strip().split('_')[-1],'')\n",
        "    if data_set == 'WS':\n",
        "      if sname.find('Normal') == -1:\n",
        "        v_type = 'Abnormal'\n",
        "        v_name = sname.replace('Abnormal_','')\n",
        "      elif sname.find('Abnormal') == -1:\n",
        "        v_type = 'Normal'\n",
        "        v_name = sname.replace('Normal_','')\n",
        "      else:\n",
        "        print('SOMETHING WRONG WHILE GETING THE VIDEO FILE NAME FOR THE SEGMENT : {}'.format(sname))\n",
        "        sys.exit()\n",
        "      v_name = v_name.replace('.txt','.mp4')\n",
        "      v_name = v_name.replace('_'+v_name.strip().split('_')[-1],'')\n",
        "    v_path = root_path_for_videos_directory+v_type+'/'+v_name\n",
        "    cap = cv2.VideoCapture(v_path)\n",
        "    NFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    NFrames = int(NFrames)\n",
        "    cap.release()\n",
        "    if NFrames <= 1024:\n",
        "      NFrames = NFrames + (1056 - NFrames)\n",
        "\n",
        "    frame_level_true_labels_v = list(np.ones(NFrames) * -1)\n",
        "    if int(TA_dict[v_type+'_'+v_name][0]) != -1 :\n",
        "      l = len(TA_dict[v_type+'_'+v_name])\n",
        "      index = 0\n",
        "      while index < l:\n",
        "        si = TA_dict[v_type+'_'+v_name][index]\n",
        "        ei = TA_dict[v_type+'_'+v_name][index+1]\n",
        "        for fn in range(int(si),min(int(ei),NFrames),1):\n",
        "          try:\n",
        "            frame_level_true_labels_v[fn] = 1\n",
        "          except:\n",
        "            print(\"WORNING: RUNTIME ERROR: IndexError\")\n",
        "            print(\"video name: \"+v_name)\n",
        "            print(\"current frame index to assign the label: {}\".format(fn))\n",
        "            print(\"Starting frame index: {}, Ending frame index: {} for current abnormal video portion\".format(int(si),int(ei)))\n",
        "            print(\"Actual number of frames in video folder: {}\".format(NFrames))\n",
        "        index = index+2\n",
        "    FLTrueLabels = FLTrueLabels + frame_level_true_labels_v\n",
        "  return FLTrueLabels"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFYtoT7rLk_8"
      },
      "source": [
        "# This code is used to execute while finding the hyperparameters\n",
        "def train_and_testing(videos_path, segment_level_labels_file_path, dataset, labels,root_path_for_videos_directory,data_set_name):\n",
        "  parameters_list1 = [1.01] #[0.01, 0.03, 0.05, 0.07, 0.09, 0.1]\n",
        "  parameters_list2 = [1.01] #[0.01, 0.03, 0.05, 0.07, 0.09, 0.1]\n",
        "  parameters_list3 = [1.03] #[0.01, 0.03, 0.05, 0.07, 0.09, 0.1]\n",
        "  parameters_list4 = [0.9] #[0.01, 0.03, 0.05, 0.07, 0.09, 0.1]\n",
        "  lambda1 = 0.5\n",
        "  lambda2a = 0.5\n",
        "  lambda2b = 0.5\n",
        "  lambda3 = 0.09 \n",
        "  DoSs = [60.0] #[1.0, 5.0, 10.0, 15.0, 20.0, 25.0, 30.0, 40.0, 60.0, 70.0, 80.0]\n",
        "  output = []\n",
        "  for lambda1 in parameters_list1:\n",
        "    for lambda2a in parameters_list2:\n",
        "      for lambda2b in parameters_list3:\n",
        "        for lambda3 in parameters_list4:\n",
        "          for DoS in DoSs:\n",
        "            iters = 20 #20 # No of times the model has to be run for each DoS value\n",
        "            results = []\n",
        "            results_f = []\n",
        "            for it_num in range(iters):\n",
        "              print(\"DoS: {}    Iter No: {} \".format(DoS,it_num))\n",
        "              time_before = datetime.now()\n",
        "              l = Labeled_and_Unlabeled_datapreparation(DoS, videos_path, segment_level_labels_file_path, dataset, labels)\n",
        "              '''\n",
        "              0 - labeled_video_samples\n",
        "              1 - unlabeled_video_samples \n",
        "              2 - actual_labels_of_labeled_samples_points\n",
        "              3 - actual_labels_of_unlabeled_samples_points\n",
        "              4 - labeled_samples_indices\n",
        "              5 - unlabeled_samples_indices\n",
        "              6 - PLP\n",
        "              7 - NLP\n",
        "              8 - ULP\n",
        "              '''\n",
        "              print('   {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(len(l[0]),len(l[1]),len(l[2]),len(l[3]),len(l[4]),len(l[5]),l[6],l[7],l[8]))\n",
        "              #X_Train = np.float32(l[0])\n",
        "              print(\"   Shape of labeled_video_samples: {}\".format(np.shape(np.float32(l[0]))))\n",
        "              #y_train = np.int8(l[2])\n",
        "              print(\"   Shape of actual_labels_of_labeled_samples_points: {}\".format(np.shape(np.int8(l[2]))))\n",
        "              #X_Test = np.float32(l[1])\n",
        "              print(\"   Shape of unlabeled_video_samples: {}\".format(np.shape(np.float32(l[1]))))\n",
        "              #y_test = np.int8(l[3])\n",
        "              print(\"   Shape of actual_labels_of_unlabeled_samples_points: {}\".format(np.shape(np.int8(l[3]))))\n",
        "              print(\"   Number of positive labeld Instances: {}\".format(l[6]))\n",
        "              print(\"   Number of negative labeld Instances: {}\".format(l[7]))\n",
        "              print(\"   Number of unlabeld Instances: {}\".format(l[8]))\n",
        "              \n",
        "              #\"Construction of K-NN graph\"\n",
        "              print(\"   SIMILARITY WEIGHT MATRIX CONSTRUCTION...\")\n",
        "              dataset1 = l[0]+l[1]\n",
        "              #print('length of l[0] : '.format(len(l[0])))\n",
        "              #print('lenght of dataset is : '.format(len(dataset1)))\n",
        "              neighbors = 6\n",
        "              time_before = datetime.now() # starting time for graph construction\n",
        "              nbrs_graph = NearestNeighbors(n_neighbors=neighbors, algorithm='ball_tree', metric = 'euclidean',n_jobs = 24).fit(np.array(dataset1))  #keyword argument 'algorithm', which must be one of ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "              distances, indices = nbrs_graph.kneighbors(np.array(dataset1))\n",
        "              neighbours_info = {}\n",
        "              for i in range(len(dataset1)):\n",
        "                nei = []\n",
        "                for j in range(neighbors):\n",
        "                  nei.append(indices[i][j])\n",
        "                neighbours_info[i] = nei\n",
        "              print(\"   SIMILARITY WEIGHT MATRIX CONSTRUCTION COMPLETED.\")\n",
        "              \n",
        "              # sparce row matrix construction for weighted similarity matrix\n",
        "              row = []\n",
        "              col = []\n",
        "              data = []\n",
        "              for i in range(len(dataset)):\n",
        "                for j in range(neighbors):\n",
        "                  if i != indices[i][j]:\n",
        "                    row.append(i)\n",
        "                    col.append(indices[i][j])\n",
        "                    data.append(distances[i][j])\n",
        "              \n",
        "              #finding connected components\n",
        "              g = Graph(len(dataset))\n",
        "              for i in range(len(dataset)):\n",
        "                for j in range(neighbors):\n",
        "                  g.addEdge(i, indices[i][j])\n",
        "              \n",
        "              cc = g.connectedComponents()\n",
        "              print('   Number of Connected Components : {}.'.format(len(cc)))\n",
        "              \n",
        "              if len(cc) > 1 :\n",
        "                for ci in range(len(cc)):\n",
        "                  test_samples = [ dataset1[e] for e in cc[ci] if e< (l[6] + l[7]) ] # collect labeled instances\n",
        "                  if len(test_samples) == 0:\n",
        "                    continue\n",
        "                  test_labeled_indices = [ e for e in cc[ci] if e< (l[6] + l[7]) ]\n",
        "                  for cj in range(len(cc)):\n",
        "                    if ci != cj:\n",
        "                      X_temp = [dataset1[j]  for j in cc[cj]]\n",
        "                      nbrs_graph = NearestNeighbors(n_neighbors=1, algorithm='ball_tree', metric='euclidean', n_jobs = 24).fit(np.array(X_temp))  #keyword argument 'algorithm', which must be one of ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "                      distance_s, indix_s = nbrs_graph.kneighbors(np.array(test_samples))\n",
        "                      distance_s = np.squeeze(distance_s)\n",
        "                      indix_s = np.squeeze(indix_s)\n",
        "                      w = min(distance_s)\n",
        "                      x_ind = list(distance_s).index(w)\n",
        "                      source_v = test_labeled_indices[ list(distance_s).index(w)]\n",
        "                      target_v = cc[cj][indix_s[x_ind]]\n",
        "                      row.append(source_v)\n",
        "                      col.append(target_v)\n",
        "                      data.append(w)\n",
        "                      g.addEdge(source_v, target_v)\n",
        "                      neighbours_info[source_v].append(target_v)\n",
        "                      #print('   Component {} and {} are connected with new edge <{}, {}>'.format(ci, cj, source_v, target_v))\n",
        "                      \n",
        "              cc = g.connectedComponents()\n",
        "              print('   After adding edges number of Connected Components are : {}.'.format(len(cc)))\n",
        "              \n",
        "              # final csr_matrix creation after making single connected components\n",
        "              total_data_points = l[6] + l[7] + l[8]\n",
        "              W = csr_matrix((np.array(data), (np.array(row), np.array(col))), shape=(total_data_points, total_data_points))\n",
        "              \n",
        "              # final csr_graph creation\n",
        "              csr_graph_of_W = csgraph_from_dense(W.toarray(), null_value=np.inf)\n",
        "              print('   GRAPH ADJACENCY MATRIX CREATED')\n",
        "              #print('CSR_Graph of W is : \\n {}'.format(csr_graph_of_W))\n",
        "              csr_GL = csgraph.laplacian(csr_graph_of_W, normed=True)\n",
        "              print('   GRAPH LAPLACIAN MATRIX CREATED')\n",
        "              #print('CSR_Graph Laplacian is :\\n {}'.format(csr_GL))\n",
        "              Iy = np.array(l[2] + l[3]).reshape(-1,32).tolist()\n",
        "              L =int( (l[6] + l[7]) / 32)\n",
        "              PL =int( l[6] /32)\n",
        "              NL = int(l[7] / 32)\n",
        "              n = l[6] + l[7] + l[8]\n",
        "              N = int(n/32)\n",
        "              \n",
        "              #O = NCGssMILP(W.toarray(), neighbours_info, neighbors, Iy, lambda1, lambda2a, lambda2b, lambda3, L,PL, NL, n, N)\n",
        "              O = NCGssMILP(W.toarray(),csr_GL, neighbours_info, Iy, lambda1, lambda2a, lambda2b, lambda3, L,PL, NL, n, N)\n",
        "              predictions = O[l[6]+l[7]:]\n",
        "              #print('Final output : {}'.format(predictions))\n",
        "              for pv in range(len(predictions)):\n",
        "                if predictions[pv] >= 0.0:\n",
        "                  predictions[pv] = 1.0\n",
        "                else:\n",
        "                  predictions[pv] = -1.0\n",
        "              # performance calculation in segment level\n",
        "              # accuracy: (tp + tn) / (p + n)\n",
        "              accuracy = accuracy_score(l[3], [round(e) for e in predictions])\n",
        "              # precision tp / (tp + fp)\n",
        "              precision = precision_score(l[3], [round(e) for e in predictions])\n",
        "              # recall: tp / (tp + fn)\n",
        "              recall = recall_score(l[3], [round(e) for e in predictions])\n",
        "              # f1: 2 tp / (2 tp + fp + fn)\n",
        "              f1 = f1_score(l[3], [round(e) for e in predictions])\n",
        "              # ROC AUC\n",
        "              auc = roc_auc_score(l[3], [round(e) for e in predictions])\n",
        "              # confusion matrix\n",
        "              matrix = confusion_matrix(l[3], [round(e) for e in predictions])\n",
        "              #print(matrix)\n",
        "              results.append([accuracy, precision, recall,f1,auc])\n",
        "              print('Seg: acc - : {}, prec - : {}, rec - : {}, f1 - : {}, auc - : {}'.format(accuracy, precision, recall, f1, auc))\n",
        "              \n",
        "              # performance calculation in frame level\n",
        "              #print(\"length of the pred and test samples {},{}\".format(len(predictions),len(l[5])))\n",
        "              flpredictions = find_frame_level_predictions_for_testdata(predictions,l[5],root_path_for_videos_directory,data_set_name)\n",
        "              #print(flpredictions)\n",
        "              fltrue_labels = find_frame_level_true_labels(frame_level_labels_file,l[5],root_path_for_videos_directory,data_set_name)\n",
        "              #print(len(flpredictions),len(fltrue_labels))\n",
        "              #print(flpredictions)\n",
        "              # accuracy: (tp + tn) / (p + n)\n",
        "              accuracy_f = accuracy_score(fltrue_labels, flpredictions)\n",
        "              # precision tp / (tp + fp)\n",
        "              precision_f = precision_score(fltrue_labels, flpredictions)\n",
        "              # recall: tp / (tp + fn)\n",
        "              recall_f = recall_score(fltrue_labels, flpredictions)\n",
        "              # f1: 2 tp / (2 tp + fp + fn)\n",
        "              f1_f = f1_score(fltrue_labels, flpredictions)\n",
        "              # ROC AUC\n",
        "              auc_f = roc_auc_score(fltrue_labels, flpredictions)\n",
        "              # confusion matrix\n",
        "              matrix_f = confusion_matrix(fltrue_labels, flpredictions)\n",
        "              #print(matrix_f)\n",
        "              results_f.append([accuracy_f, precision_f, recall_f, f1_f, auc_f])\n",
        "              print('Frame: acc - : {}, prec - : {}, rec - : {}, f1 - : {}, auc - : {}'.format(accuracy_f, precision_f, recall_f, f1_f, auc_f))\n",
        "              \n",
        "            results = list(np.mean(np.array(results),axis=0))\n",
        "            string1 = \"   Classifier: GssMILP -  NN: {} lambda1: {} lambda2a: {} lambda2b: {} lambda3: {} DoS: {} RESULTS: ACC: {} PRE: {} RECALL: {} F1-SCORE: {} AUC: {}\".format(neighbors, lambda1, lambda2a, lambda2b, lambda3, DoS, results[0], results[1], results[2], results[3], results[4])\n",
        "            print(string1)\n",
        "            \n",
        "            results_f = list(np.mean(np.array(results_f),axis=0))\n",
        "            string2 = \"   Classifier: GssMILP -  NN: {} lambda1: {} lambda2a: {} lambda2b: {} lambda3: {} DoS: {} RESULTS_F: ACC: {} PRE: {} RECALL: {} F1-SCORE: {} AUC: {}\".format(neighbors, lambda1, lambda2a, lambda2b, lambda3, DoS, results_f[0], results_f[1], results_f[2], results_f[3], results_f[4])\n",
        "            print(string2)\n",
        "            #output.append([string1,string2])       \n",
        "  return output"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph9G6BkexdyP"
      },
      "source": [
        "\"\"\"\n",
        "def train_and_testing(videos_path, segment_level_labels_file_path, dataset, labels,root_path_for_videos_directory,data_set_name):\n",
        "  lambda1 = 0.5\n",
        "  lambda2a = 0.5\n",
        "  lambda2b = 0.5\n",
        "  lambda3 = 0.09 \n",
        "  DoSs = [20.0]#[1.0, 5.0, 10.0, 15.0, 20.0, 25.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0]\n",
        "  output = []\n",
        "  for DoS in DoSs:\n",
        "    iters = 1 #20 # No of times the model has to be run for each DoS value\n",
        "    results = []\n",
        "    results_f = []\n",
        "    for it_num in range(iters):\n",
        "      print(\"DoS: {}    Iter No: {} \".format(DoS,it_num))\n",
        "      time_before = datetime.now()\n",
        "      l = Labeled_and_Unlabeled_datapreparation(DoS, videos_path, segment_level_labels_file_path, dataset, labels)\n",
        "      '''\n",
        "      0 - labeled_video_samples\n",
        "      1 - unlabeled_video_samples \n",
        "      2 - actual_labels_of_labeled_samples_points\n",
        "      3 - actual_labels_of_unlabeled_samples_points\n",
        "      4 - labeled_samples_indices\n",
        "      5 - unlabeled_samples_indices\n",
        "      6 - PLP\n",
        "      7 - NLP\n",
        "      8 - ULP\n",
        "      '''\n",
        "      print('   {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(len(l[0]),len(l[1]),len(l[2]),len(l[3]),len(l[4]),len(l[5]),l[6],l[7],l[8]))\n",
        "      #X_Train = np.float32(l[0])\n",
        "      print(\"   Shape of labeled_video_samples: {}\".format(np.shape(np.float32(l[0]))))\n",
        "      #y_train = np.int8(l[2])\n",
        "      print(\"   Shape of actual_labels_of_labeled_samples_points: {}\".format(np.shape(np.int8(l[2]))))\n",
        "      #X_Test = np.float32(l[1])\n",
        "      print(\"   Shape of unlabeled_video_samples: {}\".format(np.shape(np.float32(l[1]))))\n",
        "      #y_test = np.int8(l[3])\n",
        "      print(\"   Shape of actual_labels_of_unlabeled_samples_points: {}\".format(np.shape(np.int8(l[3]))))\n",
        "      print(\"   Number of positive labeld Instances: {}\".format(l[6]))\n",
        "      print(\"   Number of negative labeld Instances: {}\".format(l[7]))\n",
        "      print(\"   Number of unlabeld Instances: {}\".format(l[8]))\n",
        "\n",
        "      #\"Construction of K-NN graph\"\n",
        "      print(\"   SIMILARITY WEIGHT MATRIX CONSTRUCTION...\")\n",
        "      dataset1 = l[0]+l[1]\n",
        "      #print('length of l[0] : '.format(len(l[0])))\n",
        "      #print('lenght of dataset is : '.format(len(dataset1)))\n",
        "      neighbors = 6\n",
        "      time_before = datetime.now() # starting time for graph construction\n",
        "      nbrs_graph = NearestNeighbors(n_neighbors=neighbors, algorithm='ball_tree', metric = 'euclidean',n_jobs = 24).fit(np.array(dataset1))  #keyword argument 'algorithm', which must be one of ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "      distances, indices = nbrs_graph.kneighbors(np.array(dataset1))\n",
        "      #print(\"Time taken for K-NN graph construction: {}\".format(datetime.now() - time_before))\n",
        "      #print(distances)\n",
        "      #print(type(indices))\n",
        "      #print(indices)\n",
        "      # indices dict\n",
        "      neighbours_info = {}\n",
        "      for i in range(len(dataset1)):\n",
        "        nei = []\n",
        "        for j in range(neighbors):\n",
        "          nei.append(indices[i][j])\n",
        "        neighbours_info[i] = nei\n",
        "      print(\"   SIMILARITY WEIGHT MATRIX CONSTRUCTION COMPLETED.\")\n",
        "\n",
        "      # sparce row matrix construction for weighted similarity matrix\n",
        "      row = []\n",
        "      col = []\n",
        "      data = []\n",
        "      for i in range(len(dataset)):\n",
        "        for j in range(neighbors):\n",
        "          if i != indices[i][j]:\n",
        "            row.append(i)\n",
        "            col.append(indices[i][j])\n",
        "            data.append(distances[i][j])\n",
        "      \n",
        "\n",
        "      #finding connected components\n",
        "      g = Graph(len(dataset))\n",
        "      for i in range(len(dataset)):\n",
        "        for j in range(neighbors):\n",
        "          g.addEdge(i, indices[i][j])\n",
        "\n",
        "      cc = g.connectedComponents() \n",
        "      print('   Number of Connected Components : {}.'.format(len(cc)))\n",
        "      #print(\"Following are connected components\")\n",
        "      #for c in range(len(cc)):\n",
        "      #  print(cc[c])\n",
        "      if len(cc) > 1 :\n",
        "        for ci in range(len(cc)):\n",
        "          test_samples = [ dataset1[e] for e in cc[ci] if e< (l[6] + l[7]) ] # collect labeled instances\n",
        "          if len(test_samples) == 0:\n",
        "            #print('*** The connected component {} does not has labeled samples **'.format(ci))\n",
        "            #print('Nodes in this component is :\\n {} '.format(cc[ci]))\n",
        "            continue\n",
        "          else:\n",
        "            #print('   *** The connected component {} has labeled samples **'.format(ci))\n",
        "            pass\n",
        "          test_labeled_indices = [ e for e in cc[ci] if e< (l[6] + l[7]) ]\n",
        "          for cj in range(len(cc)):\n",
        "            if ci != cj:\n",
        "              X_temp = [dataset1[j]  for j in cc[cj]]\n",
        "              nbrs_graph = NearestNeighbors(n_neighbors=1, algorithm='ball_tree', metric='euclidean', n_jobs = 24).fit(np.array(X_temp))  #keyword argument 'algorithm', which must be one of ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "              distance_s, indix_s = nbrs_graph.kneighbors(np.array(test_samples))\n",
        "              distance_s = np.squeeze(distance_s)\n",
        "              indix_s = np.squeeze(indix_s)\n",
        "              w = min(distance_s)\n",
        "              x_ind = list(distance_s).index(w)\n",
        "              source_v = test_labeled_indices[ list(distance_s).index(w)]\n",
        "              target_v = cc[cj][indix_s[x_ind]]\n",
        "              row.append(source_v)\n",
        "              col.append(target_v)\n",
        "              data.append(w)\n",
        "              g.addEdge(source_v, target_v)\n",
        "              neighbours_info[source_v].append(target_v)\n",
        "              #print('   Component {} and {} are connected with new edge <{}, {}>'.format(ci, cj, source_v, target_v))\n",
        "\n",
        "      cc = g.connectedComponents() \n",
        "      #print(\"Following are connected components\")\n",
        "      #print(cc)\n",
        "      print('   After adding edges number of Connected Components are : {}.'.format(len(cc)))\n",
        "\n",
        "      # final csr_matrix creation after making single connected components\n",
        "      total_data_points = l[6] + l[7] + l[8]\n",
        "      W = csr_matrix((np.array(data), (np.array(row), np.array(col))), shape=(total_data_points, total_data_points))\n",
        "      #print(W.toarray())\n",
        "      #print('The size of W is {}'.format(W.shape))\n",
        "\n",
        "      # final csr_graph creation\n",
        "      csr_graph_of_W = csgraph_from_dense(W.toarray(), null_value=np.inf)\n",
        "      print('   GRAPH ADJACENCY MATRIX CREATED')\n",
        "      #print('CSR_Graph of W is : \\n {}'.format(csr_graph_of_W))\n",
        "      csr_GL = csgraph.laplacian(csr_graph_of_W, normed=True)\n",
        "      print('   GRAPH LAPLACIAN MATRIX CREATED')\n",
        "      #print('CSR_Graph Laplacian is :\\n {}'.format(csr_GL))\n",
        "      Iy = np.array(l[2] + l[3]).reshape(-1,32).tolist()\n",
        "      L =int( (l[6] + l[7]) / 32)\n",
        "      PL =int( l[6] /32)\n",
        "      NL = int(l[7] / 32)\n",
        "      n = l[6] + l[7] + l[8]\n",
        "      N = int(n/32)\n",
        "\n",
        "      #O = NCGssMILP(csr_GL.toarray(), Iy, lambda1, lambda2a, lambda2b, lambda3, L,PL, NL, n, N)\n",
        "      #O = NCGssMILP(W.toarray(), indices, neighbors, Iy, lambda1, lambda2a, lambda2b, lambda3, L,PL, NL, n, N)\n",
        "      #O = NCGssMILP(W.toarray(), neighbours_info, neighbors, Iy, lambda1, lambda2a, lambda2b, lambda3, L,PL, NL, n, N)\n",
        "      O = NCGssMILP(W.toarray(),csr_GL, neighbours_info, Iy, lambda1, lambda2a, lambda2b, lambda3, L,PL, NL, n, N)\n",
        "      predictions = O[l[6]+l[7]:]\n",
        "      #print('Final output : {}'.format(predictions))\n",
        "      for pv in range(len(predictions)):\n",
        "        if predictions[pv] >= 0.0:\n",
        "          predictions[pv] = 1.0\n",
        "        else:\n",
        "          predictions[pv] = -1.0\n",
        "      # performance calculation in segment level\n",
        "      # accuracy: (tp + tn) / (p + n)\n",
        "      accuracy = accuracy_score(l[3], [round(e) for e in predictions])\n",
        "      # precision tp / (tp + fp)\n",
        "      precision = precision_score(l[3], [round(e) for e in predictions])\n",
        "      # recall: tp / (tp + fn)\n",
        "      recall = recall_score(l[3], [round(e) for e in predictions])\n",
        "      # f1: 2 tp / (2 tp + fp + fn)\n",
        "      f1 = f1_score(l[3], [round(e) for e in predictions])\n",
        "      # ROC AUC\n",
        "      auc = roc_auc_score(l[3], [round(e) for e in predictions])\n",
        "      # confusion matrix\n",
        "      matrix = confusion_matrix(l[3], [round(e) for e in predictions])\n",
        "      #print(matrix)\n",
        "      results.append([accuracy, precision, recall,f1,auc])\n",
        "\n",
        "      # performance calculation in frame level\n",
        "      #print(\"length of the pred and test samples {},{}\".format(len(predictions),len(l[5])))\n",
        "      flpredictions = find_frame_level_predictions_for_testdata(predictions,l[5],root_path_for_videos_directory,data_set_name)\n",
        "      #print(flpredictions)\n",
        "      fltrue_labels = find_frame_level_true_labels(frame_level_labels_file,l[5],root_path_for_video_frames_directory,data_set_name)\n",
        "      #print(len(flpredictions),len(fltrue_labels))\n",
        "      #print(flpredictions)\n",
        "      # accuracy: (tp + tn) / (p + n)\n",
        "      accuracy_f = accuracy_score(fltrue_labels, flpredictions)\n",
        "      # precision tp / (tp + fp)\n",
        "      precision_f = precision_score(fltrue_labels, flpredictions)\n",
        "      # recall: tp / (tp + fn)\n",
        "      recall_f = recall_score(fltrue_labels, flpredictions)\n",
        "      # f1: 2 tp / (2 tp + fp + fn)\n",
        "      f1_f = f1_score(fltrue_labels, flpredictions)\n",
        "      # ROC AUC\n",
        "      auc_f = roc_auc_score(fltrue_labels, flpredictions)\n",
        "      # confusion matrix\n",
        "      matrix_f = confusion_matrix(fltrue_labels, flpredictions)\n",
        "      #print(matrix_f)\n",
        "      results_f.append([accuracy_f, precision_f, recall_f,f1_f,auc_f])\n",
        "\n",
        "    results = list(np.mean(np.array(results),axis=0))\n",
        "    string1 = \"   Classifier: GssMILP NN: {} lambda1: {} lambda2: {} lambda3: {} DoS: {} RESULTS: ACC: {} PRE: {} RECALL: {} F1-SCORE: {} AUC: {}\".format(neighbors, lambda_1, lambda_2,lambda_4, DoS,results[0],results[1],results[2],results[3],results[4])\n",
        "    print(string1)\n",
        "\n",
        "    results_f = list(np.mean(np.array(results_f),axis=0))\n",
        "    string2 = \"   Classifier: Deep_GMIL NN: {} lambda1: {} lambda2: {} lambda3: {} DoS: {} RESULTS_F: ACC: {} PRE: {} RECALL: {} F1-SCORE: {} AUC: {}\".format(neighbors, lambda_1, lambda_2,lambda_4, DoS,results_f[0],results_f[1],results_f[2],results_f[3],results_f[4])\n",
        "    print(string2)\n",
        "    output.append([string1,string2])       \n",
        "  return output \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzbbmCsKA2vS"
      },
      "source": [
        "# creating segment level labels file. \n",
        "\n",
        "frame_level_labels_file = \"./dataset/Temporal_Anomaly_Annotation_for_full_data_of_MEM.txt\" \n",
        "root_path_for_videos_directory = './MEM_videos/'\n",
        "output_file = \"./dataset/segment_level_labels_MEM.txt\"\n",
        "data_set = 'MEM'\n",
        "find_segment_level_labels(frame_level_labels_file, root_path_for_videos_directory, output_file,data_set)\n",
        "print(\"SEGMENT LEVEL LABELS FILE IS CREATED\")\n",
        "\n",
        "# Creating Dictionary of features (of size N*4096) and Dictionary of labels (of size N*1)\n",
        "videos_path=\"./dataset/MEM_dataset_1\"#MEM_dataset_1/   Ped1_dataset_1/   WS_dataset_1/\n",
        "segment_level_labels_file_path = \"./dataset/segment_level_labels_MEM.txt\"\n",
        "features_option = 3 # either 1 or 2 or 3. 1: only C3D features considered. 2: only C3D_BICLSTM features considered. 3: Both features are considered.\n",
        "dataset, labels = combining_video_features(videos_path, segment_level_labels_file_path,features_option)\n",
        "print(\"Dataset Inf: Number of instances - {}, Number of labes {}\".format(len(dataset),len(labels)))\n",
        "print('Lenth of feature vector: {}'.format(len(dataset[0][1])))\n",
        "print(\"COMBINING VIDEO FEATURES AND PREPARATION OF DATASET IS COMPLETED.\")\n",
        "train_and_testing(videos_path, segment_level_labels_file_path, dataset, labels, root_path_for_videos_directory,data_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWB5eIusKJhC"
      },
      "source": [
        "# RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPNa6axAKJCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c2525b-e556-4d5b-c078-adf9501f231f"
      },
      "source": [
        "cd /content/drive/My Drive/NSK/GssMILP_Results"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/NSK/GssMILP_Results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDAhjUq2KSMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4723c89-c259-45c8-a986-6bc19c59ba13"
      },
      "source": [
        "!cat MEM_results_on_C3D_features.txt | grep -E 'Classifier'"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 1.0 RESULTS: ACC: 0.9280172413793103 PRE: 0.780752375115761 RECALL: 0.9497436246440456 F1-SCORE: 0.8569802494249539 AUC: 0.9356933187937928\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 1.0 RESULTS_F: ACC: 0.902384149456207 PRE: 0.7080606862927661 RECALL: 0.9227835637947784 F1-SCORE: 0.8012105914038268 AUC: 0.9098476450835682\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 5.0 RESULTS: ACC: 0.926293103448276 PRE: 0.7741214616150156 RECALL: 0.9460045934399618 F1-SCORE: 0.851454012887444 AUC: 0.9333145750873975\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 5.0 RESULTS_F: ACC: 0.9002806378118515 PRE: 0.7033320183437549 RECALL: 0.9158421905027143 F1-SCORE: 0.7955941170728674 AUC: 0.9059832258927379\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 10.0 RESULTS: ACC: 0.9243055555555557 PRE: 0.7715597886316595 RECALL: 0.9435566850895907 F1-SCORE: 0.8488825992460596 AUC: 0.9311114527901714\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 10.0 RESULTS_F: ACC: 0.8987850369750724 PRE: 0.7015907215731457 RECALL: 0.9151582330506155 F1-SCORE: 0.7941779628105238 AUC: 0.9047591024009721\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 15.0 RESULTS: ACC: 0.924 PRE: 0.7741188866656602 RECALL: 0.9435633380122244 F1-SCORE: 0.850310497000627 AUC: 0.9308789543669114\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 15.0 RESULTS_F: ACC: 0.8975904565833307 PRE: 0.707642650624081 RECALL: 0.9127331874466961 F1-SCORE: 0.7968954857849309 AUC: 0.9030683431465569\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 20.0 RESULTS: ACC: 0.9244791666666666 PRE: 0.7518406994774487 RECALL: 0.9513051644240578 F1-SCORE: 0.8398251316166636 AUC: 0.9343567710916287\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 20.0 RESULTS_F: ACC: 0.8971850519922622 PRE: 0.6754472913624793 RECALL: 0.9233587882045512 F1-SCORE: 0.7799809632978779 AUC: 0.9070852318210123\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 25.0 RESULTS: ACC: 0.9266304347826086 PRE: 0.7730070280747723 RECALL: 0.9514500210187788 F1-SCORE: 0.852931000209392 AUC: 0.9354285849663044\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 25.0 RESULTS_F: ACC: 0.9002070603180687 PRE: 0.7017777234545282 RECALL: 0.9280858474929492 F1-SCORE: 0.7990594323375333 AUC: 0.9103601257549012\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 30.0 RESULTS: ACC: 0.925297619047619 PRE: 0.7777665075595802 RECALL: 0.9472968092075366 F1-SCORE: 0.8541425780463833 AUC: 0.9329197492084722\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 30.0 RESULTS_F: ACC: 0.8990461715263152 PRE: 0.7061715970498466 RECALL: 0.9232310233217291 F1-SCORE: 0.8001350492171314 AUC: 0.9077133311716757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZEc7xpSKcsw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80275fbd-e0e9-4358-e01b-617a6ea2922d"
      },
      "source": [
        "!cat MEM_results_on_C3D_BICLSTM_features.txt | grep -E 'Classifier'"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 1.0 RESULTS: ACC: 0.18405172413793106 PRE: 0.09728916955220442 RECALL: 0.33112699153818287 F1-SCORE: 0.15033988898999953 AUC: 0.23712699693912082\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 1.0 RESULTS_F: ACC: 0.22002010516782672 PRE: 0.0998367397935298 RECALL: 0.3464399138521538 F1-SCORE: 0.15496993903767173 AUC: 0.2668118217686142\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 5.0 RESULTS: ACC: 0.18469827586206894 PRE: 0.09979076000514563 RECALL: 0.3223760463440323 F1-SCORE: 0.15235897838756146 AUC: 0.2333087225541745\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 5.0 RESULTS_F: ACC: 0.2193822313437152 PRE: 0.10062253585730671 RECALL: 0.3360188852045935 F1-SCORE: 0.15483245038166188 AUC: 0.2619274067101607\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 10.0 RESULTS: ACC: 0.2462962962962963 PRE: 0.1282176532956408 RECALL: 0.38907740846248673 F1-SCORE: 0.19279703523392905 AUC: 0.2961940774409693\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 10.0 RESULTS_F: ACC: 0.2739614997410377 PRE: 0.12748044399163794 RECALL: 0.4034608523710036 F1-SCORE: 0.1936449088199513 AUC: 0.32084592933166345\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 15.0 RESULTS: ACC: 0.3415 PRE: 0.15661131977846482 RECALL: 0.46604758976399985 F1-SCORE: 0.23436330541438294 AUC: 0.3865752606198584\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 15.0 RESULTS_F: ACC: 0.36623855529170835 PRE: 0.15768815980077364 RECALL: 0.4745074882387058 F1-SCORE: 0.23668898546895328 AUC: 0.4061625002552806\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 20.0 RESULTS: ACC: 0.33359375 PRE: 0.13379198293568267 RECALL: 0.4166979043075772 F1-SCORE: 0.2022911200154207 AUC: 0.3647146257267262\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 20.0 RESULTS_F: ACC: 0.35957722664097647 PRE: 0.13320695106197294 RECALL: 0.4341826388654349 F1-SCORE: 0.2036113884136518 AUC: 0.3883145235477393\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 25.0 RESULTS: ACC: 0.3758152173913043 PRE: 0.13661813717863716 RECALL: 0.3366712676182781 F1-SCORE: 0.19338027764026872 AUC: 0.3620853248620308\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 25.0 RESULTS_F: ACC: 0.4003795883150934 PRE: 0.1386998111353352 RECALL: 0.35613205868326764 F1-SCORE: 0.1983769167642375 AUC: 0.3845393191985622\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 25.0 RESULTS: ACC: 0.3826766304347826 PRE: 0.14402136118668807 RECALL: 0.3525524758759365 F1-SCORE: 0.20395504655502178 AUC: 0.372263504192614\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 25.0 RESULTS_F: ACC: 0.4044251464533491 PRE: 0.14437831575127633 RECALL: 0.36426516715014456 F1-SCORE: 0.20640584032424533 AUC: 0.38996015765163167\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 30.0 RESULTS: ACC: 0.4916666666666666 PRE: 0.24101715286431752 RECALL: 0.5324396492211514 F1-SCORE: 0.33144991897224924 AUC: 0.5054770637354177\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 30.0 RESULTS_F: ACC: 0.504346099478404 PRE: 0.23324811213124796 RECALL: 0.5344162529285849 F1-SCORE: 0.32435554138168277 AUC: 0.5147968034853893\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 40.0 RESULTS: ACC: 0.5426215277777777 PRE: 0.23617932395198182 RECALL: 0.4743648589396142 F1-SCORE: 0.3115803343947769 AUC: 0.5193157251354987\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 40.0 RESULTS_F: ACC: 0.5415639864110634 PRE: 0.2148395985835824 RECALL: 0.44751362499755853 F1-SCORE: 0.2876326415292567 AUC: 0.5076832860838988\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 60.0 RESULTS: ACC: 0.55859375 PRE: 0.2598418332 RECALL: 0.5472873864 F1-SCORE: 0.3517152156 AUC: 0.5545877215\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 60.0 RESULTS_F: ACC: 0.5581004389 PRE: 0.2558197289 RECALL: 0.5632582575 F1-SCORE: 0.3509433271 AUC: 0.5602279928\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 70.0 RESULTS: ACC: 0.7145182292 PRE: 0.4098969852 RECALL: 0.7883123624 F1-SCORE: 0.5359568898 AUC: 0.7419775371\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 70.0 RESULTS_F: ACC: 0.6854761695 PRE: 0.3522425033 RECALL: 0.7659567508 F1-SCORE: 0.4791372185 AUC: 0.7163869677\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 80.0 RESULTS: ACC: 0.7395833333 PRE: 0.4013098534 RECALL: 0.7646062748 F1-SCORE: 0.5232119036 AUC: 0.7498276356\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 80.0 RESULTS_F: ACC: 0.7137318184 PRE: 0.3780014206 RECALL: 0.7412685842 F1-SCORE: 0.4974268808 AUC: 0.7238145226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozcxdqt_Kp36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d7cc5eb-7509-4131-d015-80e32d3f530c"
      },
      "source": [
        "!cat MEM_results_on_both_features.txt | grep -E 'Classifier'"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 1.0 RESULTS: ACC: 0.18189655172413793 PRE: 0.09710809097294906 RECALL: 0.3197404863951749 F1-SCORE: 0.14893104242484084 AUC: 0.23093896468877628\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 1.0 RESULTS_F: ACC: 0.19781711477488 PRE: 0.09805065764811008 RECALL: 0.3399771899042021 F1-SCORE: 0.15217647815247035 AUC: 0.24978100440016124\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 5.0 RESULTS: ACC: 0.1842133620689655 PRE: 0.09873133771372002 RECALL: 0.32250102134173947 F1-SCORE: 0.1511281628437406 AUC: 0.23328043793953834\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 5.0 RESULTS_F: ACC: 0.19967913993211556 PRE: 0.09936222999500784 RECALL: 0.3427555336896061 F1-SCORE: 0.15402689092750016 AUC: 0.25191096969691956\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 10.0 RESULTS: ACC: 0.2515625 PRE: 0.11551298004908706 RECALL: 0.3527481845863063 F1-SCORE: 0.17392966127235693 AUC: 0.2876600330700953\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 10.0 RESULTS_F: ACC: 0.26220943196186297 PRE: 0.1161728887034434 RECALL: 0.3751139232467061 F1-SCORE: 0.1773532924993713 AUC: 0.30345098024915196\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 15.0 RESULTS: ACC: 0.33475000000000005 PRE: 0.15235017885583074 RECALL: 0.4279736514432336 F1-SCORE: 0.22453064810323692 AUC: 0.3678853942939503\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 15.0 RESULTS_F: ACC: 0.3413682339789091 PRE: 0.14565466493236504 RECALL: 0.4339290780825584 F1-SCORE: 0.21800754108203288 AUC: 0.3751222893739023\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 20.0 RESULTS: ACC: 0.3481770833333332 PRE: 0.14994472982131085 RECALL: 0.42948855926275514 F1-SCORE: 0.22202640172681756 AUC: 0.3774461769002307\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 20.0 RESULTS_F: ACC: 0.35635025233020395 PRE: 0.14949042104347324 RECALL: 0.45404879170693724 F1-SCORE: 0.2246353309666332 AUC: 0.39242115749017836\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 25.0 RESULTS: ACC: 0.4402173913 PRE: 0.2166971904 RECALL: 0.5687415837 F1-SCORE: 0.3134539159 AUC: 0.4856275273\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 25.0 RESULTS_F: ACC: 0.4259444268 PRE: 0.1946715566 RECALL: 0.5397004039 F1-SCORE: 0.285772206 AUC: 0.4673775569\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 30.0 RESULTS: ACC: 0.4817708333333333 PRE: 0.23242333429881978 RECALL: 0.5596160804287211 F1-SCORE: 0.3278586748047855 AUC: 0.5093704047899157\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 30.0 RESULTS_F: ACC: 0.47445177806673666 PRE: 0.21327940742968804 RECALL: 0.5465208911214404 F1-SCORE: 0.3061444131179537 AUC: 0.5009026709065163\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 40.0 RESULTS: ACC: 0.5518904321 PRE: 0.2366851227 RECALL: 0.5551217709 F1-SCORE: 0.330689691 AUC: 0.553128507\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 40.0 RESULTS_F: ACC: 0.5347564798 PRE: 0.207615014 RECALL: 0.5349033727 F1-SCORE: 0.2976874417 AUC: 0.534874208\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 60.0 RESULTS: ACC: 0.5546875 PRE: 0.2439144253 RECALL: 0.5023319051 F1-SCORE: 0.3251212121 AUC: 0.5352912512\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 60.0 RESULTS_F: ACC: 0.5437767135 PRE: 0.2285013888 RECALL: 0.4968750036 F1-SCORE: 0.3111888577 AUC: 0.5260515804\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 60.0 RESULTS: ACC: 0.5583333333333333 PRE: 0.24058845517234234 RECALL: 0.5138863099331068 F1-SCORE: 0.3253136144702292 AUC: 0.5418329031226938\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 60.0 RESULTS_F: ACC: 0.5491977784898301 PRE: 0.2186895681312057 RECALL: 0.5037877324672956 F1-SCORE: 0.3027219752632416 AUC: 0.5317817683461972\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 70.0 RESULTS: ACC: 0.710546875 PRE: 0.43847080402227095 RECALL: 0.7670220460121564 F1-SCORE: 0.5543385034876689 AUC: 0.730242279950576\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 70.0 RESULTS_F: ACC: 0.6867088458346313 PRE: 0.39853319985591346 RECALL: 0.7517969187226582 F1-SCORE: 0.5168866083398558 AUC: 0.7101066640406997\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 80.0 RESULTS: ACC: 0.75546875 PRE: 0.489155332120931 RECALL: 0.7726028645855182 F1-SCORE: 0.5936920997288673 AUC: 0.7605486718062893\n",
            "   Classifier: GssMILP -  NN: 6 lambda1: 1.01 lambda2a: 1.01 lambda2b: 1.03 lambda3: 0.9 DoS: 80.0 RESULTS_F: ACC: 0.7305050994827199 PRE: 0.44939698649992366 RECALL: 0.762463378391457 F1-SCORE: 0.5611090820521512 AUC: 0.7404264665069663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSUEyYcrqdez",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6b620e34-379a-4f61-c1af-8f094d2061c0"
      },
      "source": [
        "cd /content/drive/My Drive/AnomalyDetection-v-a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AnomalyDetection-v-a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVutAC31p4LB"
      },
      "source": [
        "\"\"\"\n",
        "videos_path = './datasets/WS_dataset/videos'\n",
        "total_frames = 0\n",
        "folder_names = os.listdir(videos_path)\n",
        "video_names = []\n",
        "for f in folder_names:\n",
        "  video_names = video_names + [f+'/'+v for v in os.listdir(videos_path+'/'+f)]\n",
        "#video_names = os.listdir(videos_path)\n",
        "for v_name in video_names:\n",
        "  v_path = videos_path+'/'+v_name\n",
        "  #print(v_name)\n",
        "  cap = cv2.VideoCapture(v_path)\n",
        "  no_of_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "  no_of_frames = int(no_of_frames)\n",
        "  string = '{} {}'.format(v_name,no_of_frames)\n",
        "  print(string)\n",
        "  total_frames = total_frames + no_of_frames\n",
        "  cap.release()\n",
        "\n",
        "TA_file_path = './datasets/Temporal_Annotations_for_full_data_of_WS.txt'\n",
        "lines = open(TA_file_path,'r').readlines()\n",
        "total_positive_labeled_frames = 0\n",
        "for line in lines:\n",
        "  #print(line)\n",
        "  w = line.strip().split(' ')\n",
        "  #print(w)\n",
        "  labeled_frames = 0\n",
        "  length_of_the_line = len(w)\n",
        "  #print(length_of_the_line)\n",
        "  i = 1\n",
        "  if int(w[1]) == -1:\n",
        "    #normal video\n",
        "    pass\n",
        "  else:\n",
        "    while i < length_of_the_line-1:\n",
        "      labeled_frames = labeled_frames + (int(w[i+1]) - int(w[i]) + 1)\n",
        "      i = i+1\n",
        "  print('{} {}'.format(w[0],labeled_frames))\n",
        "  total_positive_labeled_frames = total_positive_labeled_frames + labeled_frames\n",
        "\n",
        "print('total frames: {}, total labeled frames: {}, CI: {}'.format(total_frames,total_positive_labeled_frames,(total_frames - total_positive_labeled_frames)*1.0/total_frames *100.0))\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}